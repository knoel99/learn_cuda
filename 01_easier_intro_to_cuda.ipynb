{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP7ekO6cOzWmXtAdvQF28S0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/knoel99/learn_cuda/blob/master/01_easier_intro_to_cuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# An even easier introduction to CUDA\n",
        "\n",
        "Source: https://developer.nvidia.com/blog/even-easier-introduction-cuda/\n",
        "\n",
        "Many noob notes for C++ are added."
      ],
      "metadata": {
        "id": "lzrkyjg6j-84"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements\n",
        "- Learn how to run C++ code in colab\n",
        "- Select a colab runtime with a GPU"
      ],
      "metadata": {
        "id": "N6iKmeVnfrwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test C++ code\n",
        "%%writefile hello.cpp\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "\n",
        "int main() {\n",
        "  cout << \"Hello from Colab!\" << endl;\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InVgZ75xfrPE",
        "outputId": "23d4f3a6-9377-4640-bdc5-9e4e1cfc721c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hello.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile with g++\n",
        "!g++ hello.cpp -o hello\n",
        "!./hello"
      ],
      "metadata": {
        "id": "vONiUT-HgwAU",
        "outputId": "2aaa2e38-53d7-42fb-c685-ae7e1a27f7c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from Colab!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Noob notes:\n",
        "- `<iostream>` is the library needed to print results in the terminal\n",
        "- writing `using namespace std;` allows to directly write function `cout` instead of `std::cout`\n",
        "- `cout`means \"console output\" or \"character output\""
      ],
      "metadata": {
        "id": "G60Fdwrakvi0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Addition of two arrays with standard C++ code, on CPU"
      ],
      "metadata": {
        "id": "ZqeqKJGpkHfZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial the studied function is just the addition of two arrays with 1 million elements each."
      ],
      "metadata": {
        "id": "MarZZvvqjpHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile addition.cpp\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "// Add two arrays\n",
        "void add(int n, float *x, float *y) {\n",
        "  for (int i = 0; i < n; i++)\n",
        "    y[i] = x[i] + y[i];\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "  int N = 1<<20; // 1 M elements\n",
        "\n",
        "  float *x = new float[N];\n",
        "  float *y = new float[N];\n",
        "\n",
        "  // Init the two arrays with a for loop.\n",
        "  // tutorial says : init arrays on the host => host is the CPU\n",
        "  for (int i = 0; i < N; i++) {\n",
        "    x[i] = 1.0f;\n",
        "    y[i] = 2.0f;\n",
        "  }\n",
        "\n",
        "  // Run kernel on 1M elements on the CPU\n",
        "  add(N, x, y);\n",
        "\n",
        "  // Check for errors (all elements should be 3.0f)\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < N ; i++)\n",
        "    maxError = fmax(maxError, fabs(y[i] - 3.0f));\n",
        "  std::cout << \"Max error: \" << maxError << std::endl;\n",
        "\n",
        "  // Free memory\n",
        "  delete[] x;\n",
        "  delete[] y;\n",
        "\n",
        "  return 0;\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "8tzI1vfhjoxu",
        "outputId": "cb4e8c2b-5f6f-42b9-d284-22ef1a057212",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting addition.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and run\n",
        "!g++ addition.cpp -o addition\n",
        "!./addition"
      ],
      "metadata": {
        "id": "wTma4asjkNQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4026ae05-3b0a-4780-f76f-9f2e4dbff90e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max error: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No error in the addition as expected"
      ],
      "metadata": {
        "id": "h5YsoiZVDAqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Noob note"
      ],
      "metadata": {
        "id": "R0BjiB_G5-5E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Meaning of `int N = 1<<20; `\n",
        "\n",
        "- `1<<20` means 2^20, where the double chevron means shifting bits to the left. The two arrays has 1 048 676 elements.\n",
        "- Each element of the array is a float, defined on 4 bytes.\n",
        "- Each array is then about 4*2^20 bytes=~ 4 MB in memory\n",
        "\n",
        "\n",
        "Some examples:\n",
        "- 1 << 10 = 1024 ~ 1 kB\n",
        "- 1 << 20 = 1 048 576 ~1 MB\n",
        "- 1 << 30 = 1 073 741 824  ~1 GB"
      ],
      "metadata": {
        "id": "3KHGFLzduwTI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why put the pointers in the function arguments instead of the arrays themselves, just like in python ?\n",
        "\n",
        "\n",
        "In python we have:\n",
        "```python\n",
        "def add(a, b):\n",
        "    for i in range(len(a)):\n",
        "        b[i] = a[i] + b[i]\n",
        "\n",
        "x = [1.0] * 2**20\n",
        "y = [2.0] * 2**20\n",
        "add(x, y)\n",
        "```\n",
        "\n",
        "In Cpp:\n",
        "```cpp\n",
        "void add(int n, float *x, float *y) {\n",
        "    for (int i = 0; i < n; i++)\n",
        "        y[i] = x[i] + y[i];\n",
        "}\n",
        "int N = 1<<20;\n",
        "float *x = new float[N];\n",
        "float *y = new float[N];\n",
        "\n",
        "for (int i = 0; i < N; i++) {\n",
        "  x[i] = 1.0f;\n",
        "  y[i] = 2.0f;\n",
        "}\n",
        "\n",
        "add(N, x, y);\n",
        "```\n",
        "\n",
        "In theory those two lines are equivalent, but the convention is to declare the pointer of the variable instead of the variable itself.\n",
        "\n"
      ],
      "metadata": {
        "id": "EbqcecUO6Vmd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running the addition on the GPU\n",
        "\n",
        "Now I want to run the addtion function onto the GPU, using its cores.\n",
        "\n",
        "We have to turn this C++ function into a kernel, ie a function that can run on the GPU.\n",
        "\n",
        "To do this, we just need to add the keyword `__global__` to the function. The CUDA C++ compiler can then run the function on the GPU.\n",
        "\n",
        "Defitions:\n",
        "- CUDA kernel: a function that can be run on the GPU\n",
        "- Device code: the code that runs on the GPU\n",
        "- Host code: the code that runs on the CPU\n",
        "\n",
        "Example of the tutorial:\n",
        "\n",
        "```cpp\n",
        "// Kernel function to add the elements of two arrays\n",
        "__global__\n",
        "void add(int n, float *sum, float *x, float *y) {\n",
        "  for (int i = 0; i < n; i++)\n",
        "  sum[i] = x[i] + y[i];\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "-29LiY74CvcN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Memory allocation in CUDA\n",
        "\n",
        "In standard C++, to allocate the memory for two arrays we do:\n",
        "\n",
        "```cpp\n",
        "// Init\n",
        "int N = 10;\n",
        "float *x = new float[N]:\n",
        "float *y = new float[N];\n",
        "\n",
        "// Do some stuff\n",
        "\n",
        "// Free memory\n",
        "delete[] x\n",
        "delete[] y\n",
        "```\n",
        "\n",
        "In CUDA, thanks to the Unified Memory concept, the equivalent can be written as:\n",
        "\n",
        "```cpp\n",
        "// Allocate Unified Memory --- accessible from CPU or GPU\n",
        "float *x, *y;\n",
        "cudaMallocManaged(&x, N * sizeof(float));\n",
        "cudaMallocManaged(&y, N * sizeof(float));\n",
        "\n",
        "// Do some stuff\n",
        "\n",
        "// Free memory\n",
        "cudaFree(x);\n",
        "cudaFree(y)\n",
        "```\n",
        "\n",
        "So now we have the kernel defined with the keyword `__global__` like this:\n",
        "\n",
        "```cpp\n",
        "__global__\n",
        "void add(int n, float *x, float *y){\n",
        "  ...\n",
        "}\n",
        "```\n",
        "\n",
        "And to call the kernel from the host in the `main` function, we do this:\n",
        "\n",
        "```cpp\n",
        "int main() {\n",
        "  // Stuff before\n",
        "\n",
        "  // Run kernel on 1M elements on the GPU\n",
        "  add<<<1, 1>>>(N, sum, x, y);\n",
        "\n",
        "  // Wait for the GPU to finish before accessing on host\n",
        "  cudaDeviceSynschronize();\n",
        "\n",
        "  // Stuff after\n",
        "}\n",
        "```\n",
        "\n",
        "Where `cudaDeviceSynchronize()` is needed make the CPU wait untill the computation on the GPU is finished.\n",
        "\n",
        "The complete code with the kernel is then:"
      ],
      "metadata": {
        "id": "m9Nu-BrDJYdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile add_cuda.cu\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "// Kernel function to add two arrays:\n",
        "__global__\n",
        "void add(int n, float *x, float *y){\n",
        "  for (int i = 0; i < n; i++)\n",
        "    y[i] = x[i] + y[i];\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "  int N = 1<<20;\n",
        "  float *x, *y;\n",
        "\n",
        "  // Allocate Unified Memory - accessible from CPU or GPU\n",
        "  cudaMallocManaged(&x, N * sizeof(float));\n",
        "  cudaMallocManaged(&y, N * sizeof(float));\n",
        "\n",
        "  // Init the two arrays on the host\n",
        "  for (int i = 0; i < N; i++) {\n",
        "    x[i] = 1.0f;\n",
        "    y[i] = 2.0f;\n",
        "  }\n",
        "\n",
        "  // Run kernel on 1M elements on the GPU\n",
        "  add<<<1, 1>>>(N, x, y);\n",
        "\n",
        "  cudaError_t err = cudaGetLastError();\n",
        "  if (err != cudaSuccess) {\n",
        "    std::cout << \"CUDA error: \" << cudaGetErrorString(err) << std::endl;\n",
        "  }\n",
        "\n",
        "  // Wait for the GPU to finish before accessing on host\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // Check for errors (all values should be 3.0f)\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < N; i++) {\n",
        "    maxError = fmax(maxError, fabs(y[i] - 3.0f));\n",
        "  }\n",
        "  std::cout << \"Max error: \" << maxError << std:: endl;\n",
        "\n",
        "  // Free memory\n",
        "  cudaFree(x);\n",
        "  cudaFree(y);\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwscXvVxEO9c",
        "outputId": "8e98d81a-6aca-4f6a-f311-92f97805a97e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting add_cuda.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The file below is to fix the compatibility issue between CUDA and the GPU. More details below."
      ],
      "metadata": {
        "id": "P0KnBd-ogohp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile detect_cuda_compiler.cu\n",
        "// This file is used to adapt the version\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "\n",
        "int main() {\n",
        "  int deviceCount = 0;\n",
        "  cudaGetDeviceCount(&deviceCount);\n",
        "  if (deviceCount == 0) {\n",
        "    std::cout << \"No CUDA-capable device found.\" << std::endl;\n",
        "    return 1;\n",
        "  }\n",
        "\n",
        "  cudaDeviceProp prop;\n",
        "  cudaGetDeviceProperties(&prop, 0);\n",
        "  std::cout << \"sm_\" << prop.major << prop.minor << std::endl;\n",
        "  // Output is sm_75 for T4 on Colab\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "f3JG16K9cm-9",
        "outputId": "9c82a100-6aeb-4751-98b8-78be8374515f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing detect_cuda_compiler.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this code to get the version for the option -arch=sm_xx\n",
        "%%bash\n",
        "nvcc detect_cuda_compiler.cu -o detect_cuda_compiler\n",
        "./detect_cuda_compiler\n",
        "\n",
        "ARCH=$(./detect_cuda_compiler)\n",
        "echo $ARCH\n",
        "\n",
        "nvcc -arch=$ARCH add_cuda.cu -o add_cuda\n",
        "./add_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5UyJPYCT0WK",
        "outputId": "6e8ce37e-c747-439d-9e08-39630fb5b19b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sm_75\n",
            "sm_75\n",
            "Max error: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Max error is 0, everything works well. We run our first kernel :)"
      ],
      "metadata": {
        "id": "JSe96C1nhvi0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Error due to version mismatch between the compiler nvcc and the driver of the GPU.\n",
        "\n",
        "You may get an error where the maxError is not 0 after the kernel is run. You should add this snippet to catch the CUDA error:\n",
        "\n",
        "```cpp\n",
        "// Run kernel on 1M elements on the GPU\n",
        "add<<<1, 1>>>(N, x, y);\n",
        "\n",
        "cudaError_t err = cudaGetLastError();\n",
        "if (err != cudaSuccess) {\n",
        "  std::cout << \"CUDA error: \" << cudaGetErrorString(err) << std::endl;\n",
        "}\n",
        "```\n",
        "\n",
        "For me the error was:\n",
        "```sh\n",
        "CUDA error: the provided PTX was compiled with an unsupported toolchain.\n",
        "Max error: 1\n",
        "```\n",
        "\n",
        "The code in `detect_cuda_compiler.cu` fixes the issue.\n",
        "\n",
        "### Understanding the error\n",
        "\n",
        "To understand the error is here the workflow of how a kernel is compiled and exectued on a GPU.\n",
        "\n",
        "1. The source code is written in a `.cu`file.\n",
        "\n",
        "2. The source code is compiled into PTX (Parallel Thread Exectuion), which is the equivalent of bycode in Java. The command to compile is `nvcc add_cuda.cu -o add_cuda`. CUDA source code is not directly compiled into binary code because we need to keep compatibility between the different hardware architecture (Turing, Ampere, Ada, Blackwell, etc...).\n",
        "\n",
        "3. The kernel is run with `./add_cuda`.\n",
        "\n",
        "\n",
        "In this process, multiple elements must align:\n",
        "\n",
        "- CUDA Toolkit version: this is the version that appears when running `nvcc --version`.\n",
        "- Driver CUDA Capability version: this is also called Max Supported CUDA version. This is the version that appears when running `nvidia-smi` (smi means system management interface).\n",
        "- Compute Capability: this is the version of the architecture of the hardware. This is the version that appears when running `nvidia-smi --query-gpu=compute_cap --format=csv`\n",
        "\n"
      ],
      "metadata": {
        "id": "-_T0iKQXXaD3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```bash\n",
        "Options for steering GPU code generation.\n",
        "=========================================\n",
        "\n",
        "--gpu-architecture <arch>                       (-arch)                         \n",
        "        Specify the name of the class of NVIDIA 'virtual' GPU architecture for which\n",
        "        the CUDA input files must be compiled.\n",
        "        With the exception as described for the shorthand below, the architecture\n",
        "        specified with this option must be a 'virtual' architecture (such as compute_50).\n",
        "        Normally, this option alone does not trigger assembly of the generated PTX\n",
        "        for a 'real' architecture (that is the role of nvcc option '--gpu-code',\n",
        "        see below); rather, its purpose is to control preprocessing and compilation\n",
        "        of the input to PTX.\n",
        "        For convenience, in case of simple nvcc compilations, the following shorthand\n",
        "        is supported.  If no value for option '--gpu-code' is specified, then the\n",
        "        value of this option defaults to the value of '--gpu-architecture'.  In this\n",
        "        situation, as only exception to the description above, the value specified\n",
        "        for '--gpu-architecture' may be a 'real' architecture (such as a sm_50),\n",
        "        in which case nvcc uses the specified 'real' architecture and its closest\n",
        "        'virtual' architecture as effective architecture values.  For example, 'nvcc\n",
        "        --gpu-architecture=sm_50' is equivalent to 'nvcc --gpu-architecture=compute_50\n",
        "        --gpu-code=sm_50,compute_50'.\n",
        "        -arch=all         build for all supported architectures (sm_*), and add PTX\n",
        "        for the highest major architecture to the generated code.\n",
        "        -arch=all-major   build for just supported major versions (sm_*0), plus the\n",
        "        earliest supported, and add PTX for the highest major architecture to the\n",
        "        generated code.\n",
        "        -arch=native      build for all architectures (sm_*) on the current system\n",
        "        Note: -arch=native, -arch=all, -arch=all-major cannot be used with the -code\n",
        "        option, but can be used with -gencode options.\n",
        "        Allowed values for this option:  'all','all-major','compute_50','compute_52',\n",
        "        'compute_53','compute_60','compute_61','compute_62','compute_70','compute_72',\n",
        "        'compute_75','compute_80','compute_86','compute_87','compute_89','compute_90',\n",
        "        'compute_90a','lto_50','lto_52','lto_53','lto_60','lto_61','lto_62','lto_70',\n",
        "        'lto_72','lto_75','lto_80','lto_86','lto_87','lto_89','lto_90','lto_90a',\n",
        "        'native','sm_50','sm_52','sm_53','sm_60','sm_61','sm_62','sm_70','sm_72',\n",
        "        'sm_75','sm_80','sm_86','sm_87','sm_89','sm_90','sm_90a'.\n",
        "\n",
        "--gpu-code <code>,...                           (-code)                         \n",
        "        Specify the name of the NVIDIA GPU to assemble and optimize PTX for.\n",
        "        nvcc embeds a compiled code image in the resulting executable for each specified\n",
        "        <code> architecture, which is a true binary load image for each 'real' architecture\n",
        "        (such as sm_50), and PTX code for the 'virtual' architecture (such as compute_50).\n",
        "        During runtime, such embedded PTX code is dynamically compiled by the CUDA\n",
        "        runtime system if no binary load image is found for the 'current' GPU.\n",
        "        Architectures specified for options '--gpu-architecture' and '--gpu-code'\n",
        "        may be 'virtual' as well as 'real', but the <code> architectures must be\n",
        "        compatible with the <arch> architecture.  When the '--gpu-code' option is\n",
        "        used, the value for the '--gpu-architecture' option must be a 'virtual' PTX\n",
        "        architecture.\n",
        "        For instance, '--gpu-architecture=compute_60' is not compatible with '--gpu-code=sm_52',\n",
        "        because the earlier compilation stages will assume the availability of 'compute_60'\n",
        "        features that are not present on 'sm_52'.\n",
        "        Allowed values for this option:  'compute_50','compute_52','compute_53',\n",
        "        'compute_60','compute_61','compute_62','compute_70','compute_72','compute_75',\n",
        "        'compute_80','compute_86','compute_87','compute_89','compute_90','compute_90a',\n",
        "        'lto_50','lto_52','lto_53','lto_60','lto_61','lto_62','lto_70','lto_72',\n",
        "        'lto_75','lto_80','lto_86','lto_87','lto_89','lto_90','lto_90a','sm_50',\n",
        "        'sm_52','sm_53','sm_60','sm_61','sm_62','sm_70','sm_72','sm_75','sm_80',\n",
        "        'sm_86','sm_87','sm_89','sm_90','sm_90a'.\n",
        "\n",
        "--list-gpu-code                                 (-code-ls)                      \n",
        "        List the non-accelerated gpu architectures (sm_XX) supported by the compiler\n",
        "        and exit. If both --list-gpu-code and --list-gpu-arch are set, the list is\n",
        "        displayed using the same format as the --generate-code value.\n",
        "\n",
        "--list-gpu-arch                                 (-arch-ls)                      \n",
        "        List the non-accelerated virtual device architectures (compute_XX) supported\n",
        "        by the compiler and exit. If both --list-gpu-code and --list-gpu-arch are\n",
        "        set, the list is displayed using the same format as the --generate-code value.\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "fHoP4JYrwVpM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Noob Note\n",
        "\n",
        "Let's check out ourselves that Unified Memory is accessile from the CPU or the GPU"
      ],
      "metadata": {
        "id": "AhmrflkMSqZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "id": "hAG-UTTyu-RJ",
        "outputId": "ab48c0c4-46f5-4d6c-e1f3-62d2086a7922",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --list-gpu-code"
      ],
      "metadata": {
        "id": "aXjsx9eZX1wq",
        "outputId": "55c477c6-e392-4934-830f-d8ef4198c0ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sm_50\n",
            "sm_52\n",
            "sm_53\n",
            "sm_60\n",
            "sm_61\n",
            "sm_62\n",
            "sm_70\n",
            "sm_72\n",
            "sm_75\n",
            "sm_80\n",
            "sm_86\n",
            "sm_87\n",
            "sm_89\n",
            "sm_90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --list-gpu-arch"
      ],
      "metadata": {
        "id": "oDtKmVJjvCe4",
        "outputId": "af3abac7-fe9b-471c-8948-6734744c7862",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compute_50\n",
            "compute_52\n",
            "compute_53\n",
            "compute_60\n",
            "compute_61\n",
            "compute_62\n",
            "compute_70\n",
            "compute_72\n",
            "compute_75\n",
            "compute_80\n",
            "compute_86\n",
            "compute_87\n",
            "compute_89\n",
            "compute_90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -h"
      ],
      "metadata": {
        "id": "nk4BBHmNvXQ9",
        "outputId": "5a7fc69b-ae9c-4caa-ef28-b755ca71b1c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Usage  : nvcc [options] <inputfile>\n",
            "\n",
            "Options for specifying the compilation phase\n",
            "============================================\n",
            "More exactly, this option specifies up to which stage the input files must be compiled,\n",
            "according to the following compilation trajectories for different input file types:\n",
            "        .c/.cc/.cpp/.cxx : preprocess, compile, link\n",
            "        .o               : link\n",
            "        .i/.ii           : compile, link\n",
            "        .cu              : preprocess, cuda frontend, PTX assemble,\n",
            "                           merge with host C code, compile, link\n",
            "        .gpu             : cicc compile into cubin\n",
            "        .ptx             : PTX assemble into cubin.\n",
            "\n",
            "--cuda                                          (-cuda)                         \n",
            "        Compile all .cu input files to .cu.cpp.ii output.\n",
            "\n",
            "--cubin                                         (-cubin)                        \n",
            "        Compile all .cu/.gpu/.ptx input files to device-only .cubin files.  This\n",
            "        step discards the host code for each .cu input file.\n",
            "\n",
            "--fatbin                                        (-fatbin)                       \n",
            "        Compile all .cu/.gpu/.ptx/.cubin input files to device-only .fatbin files.\n",
            "        This step discards the host code for each .cu input file.\n",
            "\n",
            "--ptx                                           (-ptx)                          \n",
            "        Compile all .cu input files to device-only .ptx files.  This step discards\n",
            "        the host code for each of these input file.\n",
            "\n",
            "--optix-ir                                      (-optix-ir)                     \n",
            "        Compile CUDA source to OptiX IR (.optixir) output. The OptiX IR is only intended\n",
            "        for consumption by OptiX through appropriate APIs. This feature is not supported\n",
            "        with link-time-optimization (-dlto), the lto_NN -arch target, or with -gencode.\n",
            "\n",
            "--preprocess                                    (-E)                            \n",
            "        Preprocess all .c/.cc/.cpp/.cxx/.cu input files.\n",
            "\n",
            "--generate-dependencies                         (-M)                            \n",
            "        Generate a dependency file that can be included in a make file for the .c/.cc/.cpp/.cxx/.cu\n",
            "        input file. If -MF is specified, multiple source files are not supported,\n",
            "        and the output is written to the specified file, otherwise it is written\n",
            "        to stdout.\n",
            "\n",
            "--generate-nonsystem-dependencies               (-MM)                           \n",
            "        Same as --generate-dependencies but skip header files found in system directories\n",
            "        (Linux only).\n",
            "\n",
            "--generate-dependencies-with-compile            (-MD)                           \n",
            "        Generate a dependency file and compile the input file. The dependency file\n",
            "        can be included in a make file for the .c/.cc/.cpp/.cxx/.cu input file. \n",
            "        This option cannot be specified together with -E. \n",
            "        The dependency file name is computed as follows:\n",
            "        - If -MF is specified, then the specified file is used as the dependency\n",
            "        file name \n",
            "        - If -o is specified, the dependency file name is computed from the specified\n",
            "        file name by replacing the suffix with '.d'.\n",
            "        - Otherwise, the dependency file name is computed by replacing the input\n",
            "        file names's suffix with '.d'\n",
            "        If the dependency file name is computed based on either -MF or -o, then multiple\n",
            "        input files are not supported.\n",
            "\n",
            "--generate-nonsystem-dependencies-with-compile  (-MMD)                          \n",
            "        Same as --generate-dependencies-with-compile, but skip header files found\n",
            "        in system directories (Linux only).\n",
            "\n",
            "--dependency-output                             (-MF)                           \n",
            "        Specify the output file for the dependency file generated with -M/-MM/-MD/-MMD.\n",
            "        \n",
            "\n",
            "--generate-dependency-targets                   (-MP)                           \n",
            "        Add an empty target for each dependency.\n",
            "\n",
            "--compile                                       (-c)                            \n",
            "        Compile each .c/.cc/.cpp/.cxx/.cu input file into an object file.\n",
            "\n",
            "--device-c                                      (-dc)                           \n",
            "        Compile each .c/.cc/.cpp/.cxx/.cu input file into an object file that contains\n",
            "        relocatable device code.  It is equivalent to '--relocatable-device-code=true\n",
            "        --compile'.\n",
            "\n",
            "--device-w                                      (-dw)                           \n",
            "        Compile each .c/.cc/.cpp/.cxx/.cu input file into an object file that contains\n",
            "        executable device code.  It is equivalent to '--relocatable-device-code=false\n",
            "        --compile'.\n",
            "\n",
            "--device-link                                   (-dlink)                        \n",
            "        Link object files with relocatable device code and .ptx/.cubin/.fatbin files\n",
            "        into an object file with executable device code, which can be passed to the\n",
            "        host linker.\n",
            "\n",
            "--link                                          (-link)                         \n",
            "        This option specifies the default behavior: compile and link all inputs.\n",
            "\n",
            "--lib                                           (-lib)                          \n",
            "        Compile all inputs into object files (if necessary) and add the results to\n",
            "        the specified output library file.\n",
            "\n",
            "--run                                           (-run)                          \n",
            "        This option compiles and links all inputs into an executable, and executes\n",
            "        it.  Or, when the input is a single executable, it is executed without any\n",
            "        compilation or linking. This step is intended for developers who do not want\n",
            "        to be bothered with setting the necessary environment variables; these are\n",
            "        set temporarily by nvcc).\n",
            "\n",
            "\n",
            "File and path specifications.\n",
            "=============================\n",
            "\n",
            "--output-file <file>                            (-o)                            \n",
            "        Specify name and location of the output file.  Only a single input file is\n",
            "        allowed when this option is present in nvcc non-linking/archiving mode.\n",
            "\n",
            "--pre-include <file>,...                        (-include)                      \n",
            "        Specify header files that must be preincluded during preprocessing.\n",
            "\n",
            "--objdir-as-tempdir                             (-objtemp)                      \n",
            "        Create intermediate files in the same directory as the object file instead\n",
            "        of in the temporary directory. This option will take effect only if -c, -dc\n",
            "        or -dw is also used.\n",
            "\n",
            "--library <library>,...                         (-l)                            \n",
            "        Specify libraries to be used in the linking stage without the library file\n",
            "        extension.  The libraries are searched for on the library search paths that\n",
            "        have been specified using option '--library-path'.\n",
            "\n",
            "--define-macro <def>,...                        (-D)                            \n",
            "        Specify macro definitions to define for use during preprocessing or compilation.\n",
            "\n",
            "--undefine-macro <def>,...                      (-U)                            \n",
            "        Undefine macro definitions during preprocessing or compilation.\n",
            "\n",
            "--include-path <path>,...                       (-I)                            \n",
            "        Specify include search paths.\n",
            "\n",
            "--system-include <path>,...                     (-isystem)                      \n",
            "        Specify system include search paths.\n",
            "\n",
            "--library-path <path>,...                       (-L)                            \n",
            "        Specify library search paths.\n",
            "\n",
            "--output-directory <directory>                  (-odir)                         \n",
            "        Specify the directory of the output file.  This option is intended for letting\n",
            "        the dependency generation step (see '--generate-dependencies') generate a\n",
            "        rule that defines the target object file in the proper directory.\n",
            "\n",
            "--compiler-bindir <path>                        (-ccbin)                        \n",
            "        Specify the directory in which the host compiler executable resides.  The\n",
            "        host compiler executable name can be also specified to ensure that the correct\n",
            "        host compiler is selected.  In addition, driver prefix options ('--input-drive-prefix',\n",
            "        '--dependency-drive-prefix', or '--drive-prefix') may need to be specified,\n",
            "        if nvcc is executed in a Cygwin shell or a MinGW shell on Windows.\n",
            "\n",
            "--allow-unsupported-compiler                    (-allow-unsupported-compiler)   \n",
            "        Disable nvcc check for supported host compiler versions. Using an unsupported\n",
            "        host compiler may cause compilation failure or incorrect run time execution.\n",
            "        Use at your own risk. This option has no effect on MacOS.\n",
            "\n",
            "--archiver-binary <path>                        (-arbin)                        \n",
            "        Specify the path of the executable for the archiving tool used to createstatic\n",
            "        libraries with '--lib'. If unspecified, a platform-specific defaultis used.\n",
            "\n",
            "--cudart {none|shared|static}                   (-cudart)                       \n",
            "        Specify the type of CUDA runtime library to be used: no CUDA runtime library,\n",
            "        shared/dynamic CUDA runtime library, or static CUDA runtime library.\n",
            "        Allowed values for this option:  'none','shared','static'.\n",
            "        Default value:  'static'.\n",
            "\n",
            "--cudadevrt {none|static}                       (-cudadevrt)                    \n",
            "        Specify the type of CUDA device runtime library to be used: no CUDA device\n",
            "        runtime library, or static CUDA device runtime library.\n",
            "        Allowed values for this option:  'none','static'.\n",
            "        Default value:  'static'.\n",
            "\n",
            "--libdevice-directory <directory>               (-ldir)                         \n",
            "        Specify the directory that contains the libdevice library files when option\n",
            "        '--dont-use-profile' is used.  Libdevice library files are located in the\n",
            "        'nvvm/libdevice' directory in the CUDA toolkit.\n",
            "\n",
            "--target-directory <string>                     (-target-dir)                   \n",
            "        Specify the subfolder name in the targets directory where the default include\n",
            "        and library paths are located. \n",
            "\n",
            "--use-local-env                                 (-use-local-env)                \n",
            "        By default nvcc assumes that the MSVC environment needs to be initialized.\n",
            "        This is done by executing the appropriate command file available for the\n",
            "        MSVC installation detected or specified. Initializing the environment for\n",
            "        each nvcc invocation can add noticeable overheads. If the environment used\n",
            "        to invoke nvcc has already been configured, this option can be used to skip\n",
            "        this step.\n",
            "\n",
            "\n",
            "Options for specifying behavior of compiler/linker.\n",
            "===================================================\n",
            "\n",
            "--profile                                       (-pg)                           \n",
            "        Instrument generated code/executable for use by gprof (Linux only).\n",
            "\n",
            "--debug                                         (-g)                            \n",
            "        Generate debug information for host code.\n",
            "\n",
            "--device-debug                                  (-G)                            \n",
            "        Generate debug information for device code. If --dopt is not specified, then\n",
            "        turns off all optimizations. Don't use for profiling; use -lineinfo instead.\n",
            "\n",
            "--generate-line-info                            (-lineinfo)                     \n",
            "        Generate line-number information for device code.\n",
            "\n",
            "--optimization-info <kind>,...                  (-opt-info)                     \n",
            "        Provide optimization reports for the specified kind of optimization. The\n",
            "        following tags are supported:\n",
            "                inline: Emit remarks related to function inlining. Inlining passmay\n",
            "        be invoked multiple times by the compiler and a function notinlined in an\n",
            "        earlier pass may be inlined in a subsequent pass.\n",
            "        Allowed values for this option:  'inline'.\n",
            "\n",
            "--optimize <level>                              (-O)                            \n",
            "        Specify optimization level for host code.\n",
            "\n",
            "--dopt <kind>                                   (-dopt)                         \n",
            "        Enable device code optimization. When specified along with '-G', enables\n",
            "        limited debug information generation for optimized device code (currently,\n",
            "        only line number information). When '-G' is not specified, '-dopt=on' is\n",
            "        implicit.\n",
            "        Allowed values for this option:  'on'.\n",
            "\n",
            "--dlink-time-opt                                (-dlto)                         \n",
            "        Perform link-time optimization of device code. Link-time optimization must\n",
            "        be specified at both compile and link time; at compile time it stores high-level\n",
            "        intermediate code, then at link time it links together and optimizes the\n",
            "        intermediate code.If that intermediate is not found at link time then nothing\n",
            "        happens. Intermediate code is also stored at compile time with the --gpu-code='lto_NN'\n",
            "        target. The options -dlto -arch=sm_NN will add a lto_NN target; if you want\n",
            "        to only add a lto_NN target and not the compute_NN that -arch=sm_NN usually\n",
            "        generates, use -arch=lto_NN. The options '-dlto -dlink -ptx -o <file.ptx>'\n",
            "        will cause nvlink to generate <file.ptx>. If -o is not used, the file generated\n",
            "        will be a_dlink.dlto.ptx.\n",
            "\n",
            "--lto                                           (-lto)                          \n",
            "        Alias for -dlto.\n",
            "\n",
            "--gen-opt-lto                                   (-gen-opt-lto)                  \n",
            "        Run the optimizer passes before generating the LTO IR.\n",
            "\n",
            "--ftemplate-backtrace-limit <limit>             (-ftemplate-backtrace-limit)    \n",
            "        Set the maximum number of template instantiation notes for a single warning\n",
            "        or error to <limit>. A value of 0 is allowed, and indicates that no limit\n",
            "        should be enforced. This value is also passed to the host compiler if it\n",
            "        provides an equivalent flag.\n",
            "\n",
            "--ftemplate-depth <limit>                       (-ftemplate-depth)              \n",
            "        Set the maximum instantiation depth for template classes to <limit>. This\n",
            "        value is also passed to the host compiler if it provides an equivalent flag.\n",
            "\n",
            "--no-exceptions                                 (-noeh)                         \n",
            "        Disable exception handling for host code.\n",
            "\n",
            "--shared                                        (-shared)                       \n",
            "        Generate a shared library during linking.  Use option '--linker-options'\n",
            "        when other linker options are required for more control.\n",
            "\n",
            "--x {c|c++|cu}                                  (-x)                            \n",
            "        Explicitly specify the language for the input files, rather than letting\n",
            "        the compiler choose a default based on the file name suffix.\n",
            "        Allowed values for this option:  'c','c++','cu'.\n",
            "\n",
            "--std {c++03|c++11|c++14|c++17|c++20}           (-std)                          \n",
            "        Select a particular C++ dialect.  Note that this flag also turns on the corresponding\n",
            "        dialect flag for the host compiler.\n",
            "        Allowed values for this option:  'c++03','c++11','c++14','c++17','c++20'.\n",
            "\n",
            "--no-host-device-initializer-list               (-nohdinitlist)                 \n",
            "        Do not implicitly consider member functions of std::initializer_list as __host__\n",
            "        __device__ functions.\n",
            "\n",
            "--no-host-device-move-forward                   (-nohdmoveforward)              \n",
            "        Do not implicitly consider std::move and std::forward as __host__ __device__\n",
            "        function templates.\n",
            "\n",
            "--expt-relaxed-constexpr                        (-expt-relaxed-constexpr)       \n",
            "        Experimental flag: Allow host code to invoke __device__ constexpr functions,\n",
            "        and device code to invoke __host__ constexpr functions.Note that the behavior\n",
            "        of this flag may change in future compiler releases.\n",
            "\n",
            "--extended-lambda                               (-extended-lambda)              \n",
            "        Allow __host__, __device__ annotations in lambda declaration. \n",
            "\n",
            "--expt-extended-lambda                          (-expt-extended-lambda)         \n",
            "        Alias for -extended-lambda.\n",
            "\n",
            "--machine {64}                                  (-m)                            \n",
            "        Specify 64 bit architecture.\n",
            "        Allowed values for this option:  64.\n",
            "        Default value:  64.\n",
            "\n",
            "--m64                                           (-m64)                          \n",
            "        Equivalent to --machine=64.\n",
            "\n",
            "\n",
            "Options for passing specific phase options\n",
            "==========================================\n",
            "These allow for passing options directly to the intended compilation phase.  Using\n",
            "these, users have the ability to pass options to the lower level compilation tools,\n",
            "without the need for nvcc to know about each and every such option.\n",
            "\n",
            "--compiler-options <options>,...                (-Xcompiler)                    \n",
            "        Specify options directly to the compiler/preprocessor.\n",
            "\n",
            "--linker-options <options>,...                  (-Xlinker)                      \n",
            "        Specify options directly to the host linker.\n",
            "\n",
            "--archive-options <options>,...                 (-Xarchive)                     \n",
            "        Specify options directly to library manager.\n",
            "\n",
            "--ptxas-options <options>,...                   (-Xptxas)                       \n",
            "        Specify options directly to ptxas, the PTX optimizing assembler.\n",
            "\n",
            "--nvlink-options <options>,...                  (-Xnvlink)                      \n",
            "        Specify options directly to nvlink.\n",
            "\n",
            "\n",
            "Miscellaneous options for guiding the compiler driver.\n",
            "======================================================\n",
            "\n",
            "--forward-unknown-to-host-compiler              (-forward-unknown-to-host-compiler)\n",
            "        Forward unknown options to the host compiler. An 'unknown option' is a command\n",
            "        line argument that starts with '-' followed by another character, and is\n",
            "        not a recognized nvcc flag or an argument for a recognized nvcc flag.\n",
            "        Note: If the unknown option is followed by a separate command line argument,\n",
            "        the argument will not be forwarded, unless it begins with the '-' character.\n",
            "        E.g.\n",
            "        'nvcc -forward-unknown-to-host-compiler -foo=bar a.cu' will forward '-foo=bar'\n",
            "        to host compiler.\n",
            "        'nvcc -forward-unknown-to-host-compiler -foo bar a.cu' will report an error\n",
            "        for 'bar' argument.\n",
            "        'nvcc -forward-unknown-to-host-compiler -foo -bar a.cu' will forward '-foo'\n",
            "        and '-bar' to host compiler.\n",
            "\n",
            "--forward-unknown-to-host-linker                (-forward-unknown-to-host-linker)\n",
            "        Forward unknown options to the host linker. An 'unknown option' is a command\n",
            "        line argument that starts with '-' followed by another character, and is\n",
            "        not a recognized nvcc flag or an argument for a recognized nvcc flag.\n",
            "        Note: If the unknown option is followed by a separate command line argument,\n",
            "        the argument will not be forwarded, unless it begins with the '-' character.\n",
            "        E.g.\n",
            "        'nvcc -forward-unknown-to-host-linker -foo=bar a.cu' will forward '-foo=bar'\n",
            "        to host linker.\n",
            "        'nvcc -forward-unknown-to-host-linker -foo bar a.cu' will report an error\n",
            "        for 'bar' argument.\n",
            "        'nvcc -forward-unknown-to-host-linker -foo -bar a.cu' will forward '-foo'\n",
            "        and '-bar' to host linker.\n",
            "\n",
            "--forward-unknown-opts                          (-forward-unknown-opts)         \n",
            "        Implies the combination of options: -forward-unknown-to-host-linker and -forward-unknown-to-host-compiler.\n",
            "        E.g.\n",
            "        'nvcc -forward-unknown-opts -foo=bar a.cu' will forward '-foo=bar' to the\n",
            "        host linker and compiler.\n",
            "        'nvcc -forward-unknown-opts -foo bar a.cu' will report an error for 'bar'\n",
            "        argument.\n",
            "        'nvcc -forward-unknown-opts -foo -bar a.cu' will forward '-foo' and '-bar'\n",
            "        to the host linker and compiler.\n",
            "\n",
            "--dont-use-profile                              (-noprof)                       \n",
            "        Nvcc uses the nvcc.profiles file for compilation.  When specifying this option,\n",
            "        the profile file is not used.\n",
            "\n",
            "--dryrun                                        (-dryrun)                       \n",
            "        Do not execute the compilation commands generated by nvcc.  Instead, list\n",
            "        them.\n",
            "\n",
            "--verbose                                       (-v)                            \n",
            "        List the compilation commands generated by this compiler driver, but do not\n",
            "        suppress their execution.\n",
            "\n",
            "--threads <number>                              (-t)                            \n",
            "        Specify the maximum number of threads to be created in parallel when compiling\n",
            "        for multiple architectures. If <number> is 1 or if compiling for one architecture,\n",
            "        this option is ignored. If <number> is 0, the number of threads will be the\n",
            "        number of CPUs on the machine.\n",
            "\n",
            "--split-compile <number>                        (-split-compile)                \n",
            "        Specify the maximum amount of concurrent threads to to be utilized when running\n",
            "        compiler optimizations. If <number> is 1, this option is ignored. If <number>\n",
            "        is 0, the number of threads will be the number of CPUs on the machine.\n",
            "        This option will have minimal (if any) impact on performance of the compiled\n",
            "        binary.\n",
            "\n",
            "--split-compile-extended <number>               (-split-compile-extended)       \n",
            "        [Experimental] Specify the maximum amount of concurrent threads to to be\n",
            "        utilized when running compiler optimizations. If <number> is 1, this option\n",
            "        is ignored. If <number> is 0, the number of threads will be the number of\n",
            "        CPUs on the machine.\n",
            "        This option is a more aggressive form of split compilation, and can potentially\n",
            "        impact performance of the compiled binary.\n",
            "\n",
            "--fdevice-syntax-only                           (-fdevice-syntax-only)          \n",
            "        Ends device compilation after front-end syntax checking. This option does\n",
            "        not generate valid device code.\n",
            "\n",
            "--keep                                          (-keep)                         \n",
            "        Keep all intermediate files that are generated during internal compilation\n",
            "        steps.\n",
            "\n",
            "--keep-dir <directory>                          (-keep-dir)                     \n",
            "        Keep all intermediate files that are generated during internal compilation\n",
            "        steps in this directory.\n",
            "\n",
            "--save-temps                                    (-save-temps)                   \n",
            "        This option is an alias of '--keep'.\n",
            "\n",
            "--clean-targets                                 (-clean)                        \n",
            "        This option reverses the behavior of nvcc.  When specified, none of the compilation\n",
            "        phases will be executed.  Instead, all of the non-temporary files that nvcc\n",
            "        would otherwise create will be deleted.\n",
            "\n",
            "--time <file name>                              (-time)                         \n",
            "        Generate a comma separated value table with the time taken by each compilation\n",
            "        phase, and append it at the end of the file given as the option argument.\n",
            "        If the file is empty, the column headings are generated in the first row\n",
            "        of the table. If the file name is '-', the timing data is generated in stdout.\n",
            "\n",
            "--run-args <arguments>,...                      (-run-args)                     \n",
            "        Used in combination with option --run to specify command line arguments for\n",
            "        the executable.\n",
            "\n",
            "--input-drive-prefix <prefix>                   (-idp)                          \n",
            "        On Windows, all command line arguments that refer to file names must be converted\n",
            "        to the Windows native format before they are passed to pure Windows executables.\n",
            "        This option specifies how the current development environment represents\n",
            "        absolute paths.  Use '/cygwin/' as <prefix> for Cygwin build environments,\n",
            "        and '/' as <prefix> for MinGW.\n",
            "\n",
            "--dependency-drive-prefix <prefix>              (-ddp)                          \n",
            "        On Windows, when generating dependency files (see --generate-dependencies),\n",
            "        all file names must be converted appropriately for the instance of 'make'\n",
            "        that is used.  Some instances of 'make' have trouble with the colon in absolute\n",
            "        paths in the native Windows format, which depends on the environment in which\n",
            "        the 'make' instance has been compiled.  Use '/cygwin/' as <prefix> for a\n",
            "        Cygwin make, and '/' as <prefix> for MinGW.  Or leave these file names in\n",
            "        the native Windows format by specifying nothing.\n",
            "\n",
            "--drive-prefix <prefix>                         (-dp)                           \n",
            "        Specifies <prefix> as both --input-drive-prefix and --dependency-drive-prefix.\n",
            "\n",
            "--dependency-target-name <target>               (-MT)                           \n",
            "        Specify the target name of the generated rule when generating a dependency\n",
            "        file (see '--generate-dependencies').\n",
            "\n",
            "--no-align-double                               --no-align-double               \n",
            "        Specifies that '-malign-double' should not be passed as a compiler argument\n",
            "        on 32-bit platforms.  WARNING: this makes the ABI incompatible with the cuda's\n",
            "        kernel ABI for certain 64-bit types.\n",
            "\n",
            "--no-device-link                                (-nodlink)                      \n",
            "        Skip the device link step when linking object files.\n",
            "\n",
            "\n",
            "Options for steering GPU code generation.\n",
            "=========================================\n",
            "\n",
            "--gpu-architecture <arch>                       (-arch)                         \n",
            "        Specify the name of the class of NVIDIA 'virtual' GPU architecture for which\n",
            "        the CUDA input files must be compiled.\n",
            "        With the exception as described for the shorthand below, the architecture\n",
            "        specified with this option must be a 'virtual' architecture (such as compute_50).\n",
            "        Normally, this option alone does not trigger assembly of the generated PTX\n",
            "        for a 'real' architecture (that is the role of nvcc option '--gpu-code',\n",
            "        see below); rather, its purpose is to control preprocessing and compilation\n",
            "        of the input to PTX.\n",
            "        For convenience, in case of simple nvcc compilations, the following shorthand\n",
            "        is supported.  If no value for option '--gpu-code' is specified, then the\n",
            "        value of this option defaults to the value of '--gpu-architecture'.  In this\n",
            "        situation, as only exception to the description above, the value specified\n",
            "        for '--gpu-architecture' may be a 'real' architecture (such as a sm_50),\n",
            "        in which case nvcc uses the specified 'real' architecture and its closest\n",
            "        'virtual' architecture as effective architecture values.  For example, 'nvcc\n",
            "        --gpu-architecture=sm_50' is equivalent to 'nvcc --gpu-architecture=compute_50\n",
            "        --gpu-code=sm_50,compute_50'.\n",
            "        -arch=all         build for all supported architectures (sm_*), and add PTX\n",
            "        for the highest major architecture to the generated code.\n",
            "        -arch=all-major   build for just supported major versions (sm_*0), plus the\n",
            "        earliest supported, and add PTX for the highest major architecture to the\n",
            "        generated code.\n",
            "        -arch=native      build for all architectures (sm_*) on the current system\n",
            "        Note: -arch=native, -arch=all, -arch=all-major cannot be used with the -code\n",
            "        option, but can be used with -gencode options.\n",
            "        Allowed values for this option:  'all','all-major','compute_50','compute_52',\n",
            "        'compute_53','compute_60','compute_61','compute_62','compute_70','compute_72',\n",
            "        'compute_75','compute_80','compute_86','compute_87','compute_89','compute_90',\n",
            "        'compute_90a','lto_50','lto_52','lto_53','lto_60','lto_61','lto_62','lto_70',\n",
            "        'lto_72','lto_75','lto_80','lto_86','lto_87','lto_89','lto_90','lto_90a',\n",
            "        'native','sm_50','sm_52','sm_53','sm_60','sm_61','sm_62','sm_70','sm_72',\n",
            "        'sm_75','sm_80','sm_86','sm_87','sm_89','sm_90','sm_90a'.\n",
            "\n",
            "--gpu-code <code>,...                           (-code)                         \n",
            "        Specify the name of the NVIDIA GPU to assemble and optimize PTX for.\n",
            "        nvcc embeds a compiled code image in the resulting executable for each specified\n",
            "        <code> architecture, which is a true binary load image for each 'real' architecture\n",
            "        (such as sm_50), and PTX code for the 'virtual' architecture (such as compute_50).\n",
            "        During runtime, such embedded PTX code is dynamically compiled by the CUDA\n",
            "        runtime system if no binary load image is found for the 'current' GPU.\n",
            "        Architectures specified for options '--gpu-architecture' and '--gpu-code'\n",
            "        may be 'virtual' as well as 'real', but the <code> architectures must be\n",
            "        compatible with the <arch> architecture.  When the '--gpu-code' option is\n",
            "        used, the value for the '--gpu-architecture' option must be a 'virtual' PTX\n",
            "        architecture.\n",
            "        For instance, '--gpu-architecture=compute_60' is not compatible with '--gpu-code=sm_52',\n",
            "        because the earlier compilation stages will assume the availability of 'compute_60'\n",
            "        features that are not present on 'sm_52'.\n",
            "        Allowed values for this option:  'compute_50','compute_52','compute_53',\n",
            "        'compute_60','compute_61','compute_62','compute_70','compute_72','compute_75',\n",
            "        'compute_80','compute_86','compute_87','compute_89','compute_90','compute_90a',\n",
            "        'lto_50','lto_52','lto_53','lto_60','lto_61','lto_62','lto_70','lto_72',\n",
            "        'lto_75','lto_80','lto_86','lto_87','lto_89','lto_90','lto_90a','sm_50',\n",
            "        'sm_52','sm_53','sm_60','sm_61','sm_62','sm_70','sm_72','sm_75','sm_80',\n",
            "        'sm_86','sm_87','sm_89','sm_90','sm_90a'.\n",
            "\n",
            "--generate-code <specification>,...             (-gencode)                      \n",
            "        This option provides a generalization of the '--gpu-architecture=<arch> --gpu-code=<code>,\n",
            "        ...' option combination for specifying nvcc behavior with respect to code\n",
            "        generation.  Where use of the previous options generates code for different\n",
            "        'real' architectures with the PTX for the same 'virtual' architecture, option\n",
            "        '--generate-code' allows multiple PTX generations for different 'virtual'\n",
            "        architectures.  In fact, '--gpu-architecture=<arch> --gpu-code=<code>,\n",
            "        ...' is equivalent to '--generate-code arch=<arch>,code=<code>,...'.\n",
            "        '--generate-code' options may be repeated for different virtual architectures.\n",
            "        Allowed keywords for this option:  'arch','code'.\n",
            "\n",
            "--relocatable-device-code {true|false}          (-rdc)                          \n",
            "        Enable (disable) the generation of relocatable device code.  If disabled,\n",
            "        executable device code is generated.  Relocatable device code must be linked\n",
            "        before it can be executed.\n",
            "        Default value:  false.\n",
            "\n",
            "--entries entry,...                             (-e)                            \n",
            "        Specify the global entry functions for which code must be generated.  By\n",
            "        default, code will be generated for all entry functions.\n",
            "\n",
            "--maxrregcount <amount>                         (-maxrregcount)                 \n",
            "        Specify the maximum amount of registers that GPU functions can use.\n",
            "        Until a function-specific limit, a higher value will generally increase the\n",
            "        performance of individual GPU threads that execute this function.  However,\n",
            "        because thread registers are allocated from a global register pool on each\n",
            "        GPU, a higher value of this option will also reduce the maximum thread block\n",
            "        size, thereby reducing the amount of thread parallelism.  Hence, a good maxrregcount\n",
            "        value is the result of a trade-off.\n",
            "        If this option is not specified, then no maximum is assumed.\n",
            "        Value less than the minimum registers required by ABI will be bumped up by\n",
            "        the compiler to ABI minimum limit.\n",
            "        User program may not be able to make use of all registers as some registers\n",
            "        are reserved by compiler.\n",
            "\n",
            "--use_fast_math                                 (-use_fast_math)                \n",
            "        Make use of fast math library.  '--use_fast_math' implies '--ftz=true --prec-div=false\n",
            "        --prec-sqrt=false --fmad=true'.\n",
            "\n",
            "--ftz {true|false}                              (-ftz)                          \n",
            "        This option controls single-precision denormals support. '--ftz=true' flushes\n",
            "        denormal values to zero and '--ftz=false' preserves denormal values. '--use_fast_math'\n",
            "        implies '--ftz=true'.\n",
            "        Default value:  false.\n",
            "\n",
            "--prec-div {true|false}                         (-prec-div)                     \n",
            "        This option controls single-precision floating-point division and reciprocals.\n",
            "        '--prec-div=true' enables the IEEE round-to-nearest mode and '--prec-div=false'\n",
            "        enables the fast approximation mode.  '--use_fast_math' implies '--prec-div=false'.\n",
            "        Default value:  true.\n",
            "\n",
            "--prec-sqrt {true|false}                        (-prec-sqrt)                    \n",
            "        This option controls single-precision floating-point squre root.  '--prec-sqrt=true'\n",
            "        enables the IEEE round-to-nearest mode and '--prec-sqrt=false' enables the\n",
            "        fast approximation mode.  '--use_fast_math' implies '--prec-sqrt=false'.\n",
            "        Default value:  true.\n",
            "\n",
            "--fmad {true|false}                             (-fmad)                         \n",
            "        This option enables (disables) the contraction of floating-point multiplies\n",
            "        and adds/subtracts into floating-point multiply-add operations (FMAD, FFMA,\n",
            "        or DFMA).  '--use_fast_math' implies '--fmad=true'.\n",
            "        Default value:  true.\n",
            "\n",
            "--extra-device-vectorization                    (-extra-device-vectorization)   \n",
            "        This option enables more aggressive device code vectorization.\n",
            "\n",
            "\n",
            "Options for steering cuda compilation.\n",
            "======================================\n",
            "\n",
            "--default-stream {legacy|null|per-thread}       (-default-stream)               \n",
            "        Specify the stream that CUDA commands from the compiled program will be sent\n",
            "        to by default.\n",
            "                \n",
            "        legacy\n",
            "                The CUDA legacy stream (per context, implicitly synchronizes with\n",
            "                other streams).\n",
            "                \n",
            "        per-thread\n",
            "                A normal CUDA stream (per thread, does not implicitly\n",
            "                synchronize with other streams).\n",
            "                \n",
            "        'null' is a deprecated alias for 'legacy'.\n",
            "                \n",
            "        Allowed values for this option:  'legacy','null','per-thread'.\n",
            "        Default value:  'legacy'.\n",
            "\n",
            "\n",
            "Generic tool options.\n",
            "=====================\n",
            "\n",
            "--disable-warnings                              (-w)                            \n",
            "        Inhibit all warning messages.\n",
            "\n",
            "--keep-device-functions                         (-keep-device-functions)        \n",
            "        In whole program compilation mode, preserve user defined external linkage\n",
            "        __device__ function definitions up to PTX.\n",
            "\n",
            "--source-in-ptx                                 (-src-in-ptx)                   \n",
            "        Interleave source in PTX. May only be used in conjunction with --device-debug\n",
            "        or --generate-line-info.\n",
            "\n",
            "--restrict                                      (-restrict)                     \n",
            "        Programmer assertion that all kernel pointer parameters are restrict pointers.\n",
            "\n",
            "--Wreorder                                      (-Wreorder)                     \n",
            "        Generate warnings when member initializers are reordered.\n",
            "\n",
            "--Wdefault-stream-launch                        (-Wdefault-stream-launch)       \n",
            "        Generate warning when an explicit stream argument is not provided in the\n",
            "        <<<...>>> kernel launch syntax.\n",
            "\n",
            "--Wmissing-launch-bounds                        (-Wmissing-launch-bounds)       \n",
            "        Generate warning when a __global__ function does not have an explicit __launch_bounds__\n",
            "        annotation.\n",
            "\n",
            "--Wext-lambda-captures-this                     (-Wext-lambda-captures-this)    \n",
            "        Generate warning when an extended lambda implicitly captures 'this'.\n",
            "\n",
            "--Wno-deprecated-declarations                   (-Wno-deprecated-declarations)  \n",
            "        Suppress warning on use of deprecated entity.\n",
            "\n",
            "--Wno-deprecated-gpu-targets                    (-Wno-deprecated-gpu-targets)   \n",
            "        Suppress warnings about deprecated GPU target architectures.\n",
            "\n",
            "--Werror <kind>,...                             (-Werror)                       \n",
            "        Make warnings of the specified kinds into errors.  The following is the list\n",
            "        of warning kinds accepted by this option:\n",
            "                \n",
            "        cross-execution-space-call\n",
            "                Be more strict about unsupported cross execution space calls.\n",
            "                The compiler will generate an error instead of a warning for a\n",
            "                call from a __host__ __device__ to a __host__ function.\n",
            "        reorder\n",
            "                Generate errors when member initializers are reordered.\n",
            "        deprecated-declarations\n",
            "                Generate error on use of a deprecated entity.\n",
            "        default-stream-launch\n",
            "                Generate error when an explicit stream argument is not provided in\n",
            "        the <<<...>>> kernel launch syntax.\n",
            "        missing-launch-bounds\n",
            "                Generate error when a __global__ function does not have an explicit\n",
            "        __launch_bounds__ annotation.\n",
            "        ext-lambda-captures-this\n",
            "                Generate error when an extended lambda implicitly captures 'this'\n",
            "        Allowed values for this option:  'all-warnings','cross-execution-space-call',\n",
            "        'default-stream-launch','deprecated-declarations','ext-lambda-captures-this',\n",
            "        'missing-launch-bounds','reorder'.\n",
            "\n",
            "--resource-usage                                (-res-usage)                    \n",
            "        Show resource usage such as registers and memory of the GPU code.\n",
            "        This option implies '--nvlink-options --verbose' when '--relocatable-device-code=true'\n",
            "        is set.  Otherwise, it implies '--ptxas-options --verbose'.\n",
            "\n",
            "--extensible-whole-program                      (-ewp)                          \n",
            "        Do extensible whole program compilation of device code.\n",
            "\n",
            "--no-compress                                   (-no-compress)                  \n",
            "        Do not compress device code in fatbinary.\n",
            "\n",
            "--qpp-config                                    (-qpp-config)                   \n",
            "        Specify the configuration ([[compiler/]version,][target]) for the q++ host\n",
            "        compiler. The argument will be forwarded to the q++ compiler with its -V\n",
            "        flag.\n",
            "\n",
            "--compile-as-tools-patch                        (-astoolspatch)                 \n",
            "        Compile patch code for CUDA tools. Implies --keep-device-functions.\n",
            "\n",
            "--list-gpu-code                                 (-code-ls)                      \n",
            "        List the non-accelerated gpu architectures (sm_XX) supported by the compiler\n",
            "        and exit. If both --list-gpu-code and --list-gpu-arch are set, the list is\n",
            "        displayed using the same format as the --generate-code value.\n",
            "\n",
            "--list-gpu-arch                                 (-arch-ls)                      \n",
            "        List the non-accelerated virtual device architectures (compute_XX) supported\n",
            "        by the compiler and exit. If both --list-gpu-code and --list-gpu-arch are\n",
            "        set, the list is displayed using the same format as the --generate-code value.\n",
            "\n",
            "--display-error-number                          (-err-no)                       \n",
            "        This option displays a diagnostic number for any message generated by the\n",
            "        CUDA frontend compiler (note: not the host compiler).\n",
            "\n",
            "--no-display-error-number                       (-no-err-no)                    \n",
            "        This option disables the display of a diagnostic number for any message generated\n",
            "        by the CUDA frontend compiler (note: not the host compiler).\n",
            "\n",
            "--diag-error <error-number>,...                 (-diag-error)                   \n",
            "        Emit error for specified diagnostic message(s) generated by the CUDA frontend\n",
            "        compiler (note: does not affect diagnostics generated by the host compiler/preprocessor).\n",
            "\n",
            "--diag-suppress <error-number>,...              (-diag-suppress)                \n",
            "        Suppress specified diagnostic message(s) generated by the CUDA frontend compiler\n",
            "        (note: does not affect diagnostics generated by the host compiler/preprocessor).\n",
            "\n",
            "--diag-warn <error-number>,...                  (-diag-warn)                    \n",
            "        Emit warning for specified diagnostic message(s) generated by the CUDA frontend\n",
            "        compiler (note: does not affect diagnostics generated by the host compiler/preprocessor).\n",
            "\n",
            "--host-linker-script {use-lcs|gen-lcs}          (-hls)                          \n",
            "        Use the host linker script (GNU/Linux only) to enable support for certain\n",
            "        CUDA specific requirements, while building executable files or shared libraries.\n",
            "                \n",
            "        use-lcs\n",
            "                Prepares a host linker script to enable host linker support \n",
            "                for relocatable device object files that are larger in size,\n",
            "                that would otherwise, in certain cases cause the host\n",
            "                linker to fail with relocation truncation error.\n",
            "        gen-lcs\n",
            "                Generates a host linker script that can be passed to host \n",
            "                linker manually, in the case where host linker is invoked \n",
            "                separately outside of nvcc. This option can be combined \n",
            "                with -shared or -r option to generate linker scripts that \n",
            "                can be used while generating host shared libraries or host \n",
            "                relocatable links respectively.\n",
            "                \n",
            "                The file generated using this option must be provided as \n",
            "                the last input file to the host linker.\n",
            "                \n",
            "                Default Output Filename: The output is generated to stdout \n",
            "                by default. Use the option -o filename to specify the \n",
            "                output filename.\n",
            "                \n",
            "        A linker script may already be in use and passed \n",
            "        to the host linker using the host linker option --script \n",
            "        (or -T), then the generated host linker script must augment \n",
            "        the existing linker script. In such cases, the option -aug-hls \n",
            "        must be used to generate linker script that contains only the \n",
            "        augmentation parts. Otherwise, the host linker behaviour is \n",
            "        undefined.\n",
            "                \n",
            "        A host linker option, such as -z with a non-default argument, \n",
            "        that can modify the default linker script internally, is \n",
            "        incompatible with this option and the behavior of any such \n",
            "        usage is undefined.\n",
            "                \n",
            "        Allowed values for this option:  'gen-lcs','use-lcs'.\n",
            "\n",
            "--augment-host-linker-script                    (-aug-hls)                      \n",
            "        Enables generation of host linker script that augments an existing host linker\n",
            "        script (GNU/Linux only). See option --host-linker-script for more details.\n",
            "\n",
            "--host-relocatable-link                         (-r)                            \n",
            "        When used in combination with -hls=gen-lcs, controls the behaviour of -hls=gen-lcs\n",
            "        and sets it to generate host linker script that can be used in host relocatable\n",
            "        link (ld -r linkage). See option -hls=gen-lcs for more information.\n",
            "                \n",
            "        This option currently is effective only when used with -hls=gen-lcs; in all\n",
            "        other cases, this option is ignored currently.\n",
            "\n",
            "--brief-diagnostics {true|false}                (-brief-diag)                   \n",
            "        This option disables or enables showing preprocessed source line and column\n",
            "        info in a diagnostic.\n",
            "        The --brief-diagnostics=true will not show the source line and column info.\n",
            "        Default value:  false.\n",
            "\n",
            "--jump-table-density <number>                   (-jtd)                          \n",
            "        This option sets the case-density threshold for jump table generation for\n",
            "        switch statements. It ranges from 0 to 101 inclusively. When the case-density\n",
            "        percentage reaches this threshold, switch statements will be converted to\n",
            "        jump tables.\n",
            "        Default value:  101.\n",
            "\n",
            "--relocatable-ptx                               (-reloc-ptx)                    \n",
            "        Insert PTX from relocatable fatbins within objects into the result fatbin.\n",
            "\n",
            "--help                                          (-h)                            \n",
            "        Print this help information on this tool.\n",
            "\n",
            "--version                                       (-V)                            \n",
            "        Print version information on this tool.\n",
            "\n",
            "--options-file <file>,...                       (-optf)                         \n",
            "        Include command line options from specified file.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "eRJBCWoFmla3",
        "outputId": "2b6aed03-10c3-4a9e-f79d-128052299620",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Nov  9 17:35:42 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -h"
      ],
      "metadata": {
        "id": "SE4oZ0DvnciI",
        "outputId": "ed481005-e893-4ec6-8927-1318e68b4f69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA System Management Interface -- v550.54.15\n",
            "\n",
            "NVSMI provides monitoring information for Tesla and select Quadro devices.\n",
            "The data is presented in either a plain text or an XML format, via stdout or a file.\n",
            "NVSMI also provides several management operations for changing the device state.\n",
            "\n",
            "Note that the functionality of NVSMI is exposed through the NVML C-based\n",
            "library. See the NVIDIA developer website for more information about NVML.\n",
            "Python wrappers to NVML are also available.  The output of NVSMI is\n",
            "not guaranteed to be backwards compatible; NVML and the bindings are backwards\n",
            "compatible.\n",
            "\n",
            "http://developer.nvidia.com/nvidia-management-library-nvml/\n",
            "http://pypi.python.org/pypi/nvidia-ml-py/\n",
            "Supported products:\n",
            "- Full Support\n",
            "    - All Tesla products, starting with the Kepler architecture\n",
            "    - All Quadro products, starting with the Kepler architecture\n",
            "    - All GRID products, starting with the Kepler architecture\n",
            "    - GeForce Titan products, starting with the Kepler architecture\n",
            "- Limited Support\n",
            "    - All Geforce products, starting with the Kepler architecture\n",
            "nvidia-smi [OPTION1 [ARG1]] [OPTION2 [ARG2]] ...\n",
            "\n",
            "    -h,   --help                Print usage information and exit.\n",
            "\n",
            "          --version             Print version information and exit.\n",
            "\n",
            "  LIST OPTIONS:\n",
            "\n",
            "    -L,   --list-gpus           Display a list of GPUs connected to the system.\n",
            "\n",
            "    -B,   --list-excluded-gpus  Display a list of excluded GPUs in the system.\n",
            "\n",
            "  SUMMARY OPTIONS:\n",
            "\n",
            "    <no arguments>              Show a summary of GPUs connected to the system.\n",
            "\n",
            "    [plus any of]\n",
            "\n",
            "    -i,   --id=                 Target a specific GPU.\n",
            "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
            "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
            "\n",
            "  QUERY OPTIONS:\n",
            "\n",
            "    -q,   --query               Display GPU or Unit info.\n",
            "\n",
            "    [plus any of]\n",
            "\n",
            "    -u,   --unit                Show unit, rather than GPU, attributes.\n",
            "    -i,   --id=                 Target a specific GPU or Unit.\n",
            "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
            "    -x,   --xml-format          Produce XML output.\n",
            "          --dtd                 When showing xml output, embed DTD.\n",
            "    -d,   --display=            Display only selected information: MEMORY,\n",
            "                                    UTILIZATION, ECC, TEMPERATURE, POWER, CLOCK,\n",
            "                                    COMPUTE, PIDS, PERFORMANCE, SUPPORTED_CLOCKS,\n",
            "                                    PAGE_RETIREMENT, ACCOUNTING, ENCODER_STATS,\n",
            "                                    SUPPORTED_GPU_TARGET_TEMP, VOLTAGE, FBC_STATS\n",
            "                                    ROW_REMAPPER, RESET_STATUS, GSP_FIRMWARE_VERSION\n",
            "                                Flags can be combined with comma e.g. ECC,POWER.\n",
            "                                Sampling data with max/min/avg is also returned \n",
            "                                for POWER, UTILIZATION and CLOCK display types.\n",
            "                                Doesn't work with -u or -x flags.\n",
            "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
            "\n",
            "    -lms, --loop-ms=            Probe until Ctrl+C at specified millisecond interval.\n",
            "\n",
            "  SELECTIVE QUERY OPTIONS:\n",
            "\n",
            "    Allows the caller to pass an explicit list of properties to query.\n",
            "\n",
            "    [one of]\n",
            "\n",
            "    --query-gpu                 Information about GPU.\n",
            "                                Call --help-query-gpu for more info.\n",
            "    --query-supported-clocks    List of supported clocks.\n",
            "                                Call --help-query-supported-clocks for more info.\n",
            "    --query-compute-apps        List of currently active compute processes.\n",
            "                                Call --help-query-compute-apps for more info.\n",
            "    --query-accounted-apps      List of accounted compute processes.\n",
            "                                Call --help-query-accounted-apps for more info.\n",
            "                                This query is not supported on vGPU host.\n",
            "    --query-retired-pages       List of device memory pages that have been retired.\n",
            "                                Call --help-query-retired-pages for more info.\n",
            "    --query-remapped-rows       Information about remapped rows.\n",
            "                                Call --help-query-remapped-rows for more info.\n",
            "\n",
            "    [mandatory]\n",
            "\n",
            "    --format=                   Comma separated list of format options:\n",
            "                                  csv - comma separated values (MANDATORY)\n",
            "                                  noheader - skip the first line with column headers\n",
            "                                  nounits - don't print units for numerical\n",
            "                                             values\n",
            "\n",
            "    [plus any of]\n",
            "\n",
            "    -i,   --id=                 Target a specific GPU or Unit.\n",
            "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
            "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
            "    -lms, --loop-ms=            Probe until Ctrl+C at specified millisecond interval.\n",
            "\n",
            "  DEVICE MODIFICATION OPTIONS:\n",
            "\n",
            "    [any one of]\n",
            "\n",
            "    -pm,  --persistence-mode=   Set persistence mode: 0/DISABLED, 1/ENABLED\n",
            "    -e,   --ecc-config=         Toggle ECC support: 0/DISABLED, 1/ENABLED\n",
            "    -p,   --reset-ecc-errors=   Reset ECC error counts: 0/VOLATILE, 1/AGGREGATE\n",
            "    -c,   --compute-mode=       Set MODE for compute applications:\n",
            "                                0/DEFAULT, 1/EXCLUSIVE_THREAD (DEPRECATED),\n",
            "                                2/PROHIBITED, 3/EXCLUSIVE_PROCESS\n",
            "          --gom=                Set GPU Operation Mode:\n",
            "                                    0/ALL_ON, 1/COMPUTE, 2/LOW_DP\n",
            "    -r    --gpu-reset           Trigger reset of the GPU.\n",
            "                                Can be used to reset the GPU HW state in situations\n",
            "                                that would otherwise require a machine reboot.\n",
            "                                Typically useful if a double bit ECC error has\n",
            "                                occurred.\n",
            "                                Reset operations are not guarenteed to work in\n",
            "                                all cases and should be used with caution.\n",
            "    -vm   --virt-mode=          Switch GPU Virtualization Mode:\n",
            "                                Sets GPU virtualization mode to 3/VGPU or 4/VSGA\n",
            "                                Virtualization mode of a GPU can only be set when\n",
            "                                it is running on a hypervisor.\n",
            "    -lgc  --lock-gpu-clocks=    Specifies <minGpuClock,maxGpuClock> clocks as a\n",
            "                                    pair (e.g. 1500,1500) that defines the range \n",
            "                                    of desired locked GPU clock speed in MHz.\n",
            "                                    Setting this will supercede application clocks\n",
            "                                    and take effect regardless if an app is running.\n",
            "                                    Input can also be a singular desired clock value\n",
            "                                    (e.g. <GpuClockValue>). Optionally, --mode can be\n",
            "                                    specified to indicate a special mode.\n",
            "    -m    --mode=               Specifies the mode for --locked-gpu-clocks.\n",
            "                                    Valid modes: 0, 1\n",
            "    -rgc  --reset-gpu-clocks\n",
            "                                Resets the Gpu clocks to the default values.\n",
            "    -lmc  --lock-memory-clocks=  Specifies <minMemClock,maxMemClock> clocks as a\n",
            "                                    pair (e.g. 5100,5100) that defines the range \n",
            "                                    of desired locked Memory clock speed in MHz.\n",
            "                                    Input can also be a singular desired clock value\n",
            "                                    (e.g. <MemClockValue>).\n",
            "    -rmc  --reset-memory-clocks\n",
            "                                Resets the Memory clocks to the default values.\n",
            "    -lmcd --lock-memory-clocks-deferred=\n",
            "                                    Specifies memClock clock to lock. This limit is\n",
            "                                    applied the next time GPU is initialized.\n",
            "                                    This is guaranteed by unloading and reloading the kernel module.\n",
            "                                    Requires root.\n",
            "    -rmcd --reset-memory-clocks-deferred\n",
            "                                Resets the deferred Memory clocks applied.\n",
            "    -ac   --applications-clocks= Specifies <memory,graphics> clocks as a\n",
            "                                    pair (e.g. 2000,800) that defines GPU's\n",
            "                                    speed in MHz while running applications on a GPU.\n",
            "    -rac  --reset-applications-clocks\n",
            "                                Resets the applications clocks to the default values.\n",
            "    -pl   --power-limit=        Specifies maximum power management limit in watts.\n",
            "                                Takes an optional argument --scope.\n",
            "    -sc   --scope=              Specifies the device type for --scope: 0/GPU, 1/TOTAL_MODULE (Grace Hopper Only)\n",
            "    -cc   --cuda-clocks=        Overrides or restores default CUDA clocks.\n",
            "                                In override mode, GPU clocks higher frequencies when running CUDA applications.\n",
            "                                Only on supported devices starting from the Volta series.\n",
            "                                Requires administrator privileges.\n",
            "                                0/RESTORE_DEFAULT, 1/OVERRIDE\n",
            "    -am   --accounting-mode=    Enable or disable Accounting Mode: 0/DISABLED, 1/ENABLED\n",
            "    -caa  --clear-accounted-apps\n",
            "                                Clears all the accounted PIDs in the buffer.\n",
            "          --auto-boost-default= Set the default auto boost policy to 0/DISABLED\n",
            "                                or 1/ENABLED, enforcing the change only after the\n",
            "                                last boost client has exited.\n",
            "          --auto-boost-permission=\n",
            "                                Allow non-admin/root control over auto boost mode:\n",
            "                                0/UNRESTRICTED, 1/RESTRICTED\n",
            "    -mig  --multi-instance-gpu= Enable or disable Multi Instance GPU: 0/DISABLED, 1/ENABLED\n",
            "                                Requires root.\n",
            "    -gtt  --gpu-target-temp=    Set GPU Target Temperature for a GPU in degree celsius.\n",
            "                                Requires administrator privileges\n",
            "\n",
            "   [plus optional]\n",
            "\n",
            "    -i,   --id=                 Target a specific GPU.\n",
            "    -eow, --error-on-warning    Return a non-zero error for warnings.\n",
            "\n",
            "  UNIT MODIFICATION OPTIONS:\n",
            "\n",
            "    -t,   --toggle-led=         Set Unit LED state: 0/GREEN, 1/AMBER\n",
            "\n",
            "   [plus optional]\n",
            "\n",
            "    -i,   --id=                 Target a specific Unit.\n",
            "\n",
            "  SHOW DTD OPTIONS:\n",
            "\n",
            "          --dtd                 Print device DTD and exit.\n",
            "\n",
            "     [plus optional]\n",
            "\n",
            "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
            "    -u,   --unit                Show unit, rather than device, DTD.\n",
            "\n",
            "    --debug=                    Log encrypted debug information to a specified file. \n",
            "\n",
            " Device Monitoring:\n",
            "    dmon                        Displays device stats in scrolling format.\n",
            "                                \"nvidia-smi dmon -h\" for more information.\n",
            "\n",
            "    daemon                      Runs in background and monitor devices as a daemon process.\n",
            "                                This is an experimental feature. Not supported on Windows baremetal\n",
            "                                \"nvidia-smi daemon -h\" for more information.\n",
            "\n",
            "    replay                      Used to replay/extract the persistent stats generated by daemon.\n",
            "                                This is an experimental feature.\n",
            "                                \"nvidia-smi replay -h\" for more information.\n",
            "\n",
            " Process Monitoring:\n",
            "    pmon                        Displays process stats in scrolling format.\n",
            "                                \"nvidia-smi pmon -h\" for more information.\n",
            "\n",
            " TOPOLOGY:\n",
            "    topo                        Displays device/system topology. \"nvidia-smi topo -h\" for more information.\n",
            "\n",
            " DRAIN STATES:\n",
            "    drain                       Displays/modifies GPU drain states for power idling. \"nvidia-smi drain -h\" for more information.\n",
            "\n",
            " NVLINK:\n",
            "    nvlink                      Displays device nvlink information. \"nvidia-smi nvlink -h\" for more information.\n",
            "\n",
            " C2C:\n",
            "    c2c                         Displays device C2C information. \"nvidia-smi c2c -h\" for more information.\n",
            "\n",
            " CLOCKS:\n",
            "    clocks                      Control and query clock information. \"nvidia-smi clocks -h\" for more information.\n",
            "\n",
            " ENCODER SESSIONS:\n",
            "    encodersessions             Displays device encoder sessions information. \"nvidia-smi encodersessions -h\" for more information.\n",
            "\n",
            " FBC SESSIONS:\n",
            "    fbcsessions                 Displays device FBC sessions information. \"nvidia-smi fbcsessions -h\" for more information.\n",
            "\n",
            " GRID vGPU:\n",
            "    vgpu                        Displays vGPU information. \"nvidia-smi vgpu -h\" for more information.\n",
            "\n",
            " MIG:\n",
            "    mig                         Provides controls for MIG management. \"nvidia-smi mig -h\" for more information.\n",
            "\n",
            " COMPUTE POLICY:\n",
            "    compute-policy              Control and query compute policies. \"nvidia-smi compute-policy -h\" for more information. \n",
            "\n",
            " BOOST SLIDER:\n",
            "    boost-slider                Control and query boost sliders. \"nvidia-smi boost-slider -h\" for more information. \n",
            "\n",
            " POWER HINT:    power-hint                  Estimates GPU power usage. \"nvidia-smi power-hint -h\" for more information. \n",
            "\n",
            " BASE CLOCKS:    base-clocks                 Query GPU base clocks. \"nvidia-smi base-clocks -h\" for more information. \n",
            "\n",
            " CONFIDENTIAL COMPUTE:\n",
            "    conf-compute                Control and query confidential compute. \"nvidia-smi conf-compute -h\" for more information. \n",
            "\n",
            " GPU PERFORMANCE MONITORING: \n",
            "    gpm                         Control and query GPU performance monitoring unit. \"nvidia-smi gpm -h\" for more information. \n",
            "\n",
            " PCI:\n",
            "    pci                         Display device PCI information. \"nvidia-smi pci -h\" for more information.\n",
            "\n",
            "Please see the nvidia-smi(1) manual page for more detailed information.\n"
          ]
        }
      ]
    }
  ]
}